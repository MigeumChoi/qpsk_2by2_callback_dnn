{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPNzfcLrBbiOtJ+VLdFMbj6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip uninstall tensorflow"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VsL1ii2_PumR","executionInfo":{"status":"ok","timestamp":1694154549831,"user_tz":-540,"elapsed":9384,"user":{"displayName":"최미금","userId":"03270121767541003919"}},"outputId":"06eb4ce5-1007-40c5-d2d9-fd097f71535d"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: tensorflow 2.13.0\n","Uninstalling tensorflow-2.13.0:\n","  Would remove:\n","    /usr/local/bin/estimator_ckpt_converter\n","    /usr/local/bin/import_pb_to_tensorboard\n","    /usr/local/bin/saved_model_cli\n","    /usr/local/bin/tensorboard\n","    /usr/local/bin/tf_upgrade_v2\n","    /usr/local/bin/tflite_convert\n","    /usr/local/bin/toco\n","    /usr/local/bin/toco_from_protos\n","    /usr/local/lib/python3.10/dist-packages/tensorflow-2.13.0.dist-info/*\n","    /usr/local/lib/python3.10/dist-packages/tensorflow/*\n","Proceed (Y/n)? y\n","  Successfully uninstalled tensorflow-2.13.0\n","\n"]}]},{"cell_type":"code","source":["!pip uninstall keras"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NpdAkfs9eQnB","executionInfo":{"status":"ok","timestamp":1694154557515,"user_tz":-540,"elapsed":5090,"user":{"displayName":"최미금","userId":"03270121767541003919"}},"outputId":"fe773dad-2182-41a1-902f-746db3bd422e"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: keras 2.13.1\n","Uninstalling keras-2.13.1:\n","  Would remove:\n","    /usr/local/lib/python3.10/dist-packages/keras-2.13.1.dist-info/*\n","    /usr/local/lib/python3.10/dist-packages/keras/*\n","Proceed (Y/n)? \n","  Successfully uninstalled keras-2.13.1\n"]}]},{"cell_type":"code","source":["!pip install tensorflow==2.13.0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oF08pTeLP-sa","executionInfo":{"status":"ok","timestamp":1694154604140,"user_tz":-540,"elapsed":42861,"user":{"displayName":"최미금","userId":"03270121767541003919"}},"outputId":"e74b1423-dc29-4a12-8a57-670e08195a00"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow==2.13.0\n","  Using cached tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (524.1 MB)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (23.5.26)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (0.4.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (0.2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.57.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (3.9.0)\n","Collecting keras<2.14,>=2.13.1 (from tensorflow==2.13.0)\n","  Using cached keras-2.13.1-py3-none-any.whl (1.7 MB)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (16.0.6)\n","Requirement already satisfied: numpy<=1.24.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.23.5)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (23.1)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.16.0)\n","Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (2.13.0)\n","Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (2.13.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (2.3.0)\n","Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (4.5.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (0.33.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.13.0) (0.41.2)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.4.4)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.31.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.7.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.3.7)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (5.3.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2023.7.22)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.1.3)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.2.2)\n","Installing collected packages: keras, tensorflow\n","Successfully installed keras-2.13.1 tensorflow-2.13.0\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dYVRGD5tON74","executionInfo":{"status":"ok","timestamp":1694233785416,"user_tz":-540,"elapsed":14891,"user":{"displayName":"최미금","userId":"03270121767541003919"}},"outputId":"bf94390b-ff51-40f8-d317-3b445e1d09bd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/3000\n","1/1 [==============================] - ETA: 0s - loss: 2.0909\n","Epoch 1: val_loss improved from inf to 2.43328, saving model to hl5_0100.h5\n","1/1 [==============================] - 1s 1s/step - loss: 2.0909 - val_loss: 2.4333\n","Epoch 2/3000\n","1/1 [==============================] - ETA: 0s - loss: 2.0814\n","Epoch 2: val_loss improved from 2.43328 to 2.42386, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 62ms/step - loss: 2.0814 - val_loss: 2.4239\n","Epoch 3/3000\n","1/1 [==============================] - ETA: 0s - loss: 2.0726\n","Epoch 3: val_loss improved from 2.42386 to 2.41367, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 72ms/step - loss: 2.0726 - val_loss: 2.4137\n","Epoch 4/3000\n","1/1 [==============================] - ETA: 0s - loss: 2.0630"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 4: val_loss improved from 2.41367 to 2.40235, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 63ms/step - loss: 2.0630 - val_loss: 2.4024\n","Epoch 5/3000\n","1/1 [==============================] - ETA: 0s - loss: 2.0523\n","Epoch 5: val_loss improved from 2.40235 to 2.38975, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 64ms/step - loss: 2.0523 - val_loss: 2.3898\n","Epoch 6/3000\n","1/1 [==============================] - ETA: 0s - loss: 2.0403\n","Epoch 6: val_loss improved from 2.38975 to 2.37578, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 70ms/step - loss: 2.0403 - val_loss: 2.3758\n","Epoch 7/3000\n","1/1 [==============================] - ETA: 0s - loss: 2.0270\n","Epoch 7: val_loss improved from 2.37578 to 2.36021, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 63ms/step - loss: 2.0270 - val_loss: 2.3602\n","Epoch 8/3000\n","1/1 [==============================] - ETA: 0s - loss: 2.0122\n","Epoch 8: val_loss improved from 2.36021 to 2.34298, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 72ms/step - loss: 2.0122 - val_loss: 2.3430\n","Epoch 9/3000\n","1/1 [==============================] - ETA: 0s - loss: 1.9956\n","Epoch 9: val_loss improved from 2.34298 to 2.32381, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 65ms/step - loss: 1.9956 - val_loss: 2.3238\n","Epoch 10/3000\n","1/1 [==============================] - ETA: 0s - loss: 1.9771\n","Epoch 10: val_loss improved from 2.32381 to 2.30250, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 64ms/step - loss: 1.9771 - val_loss: 2.3025\n","Epoch 11/3000\n","1/1 [==============================] - ETA: 0s - loss: 1.9565\n","Epoch 11: val_loss improved from 2.30250 to 2.27868, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 67ms/step - loss: 1.9565 - val_loss: 2.2787\n","Epoch 12/3000\n","1/1 [==============================] - ETA: 0s - loss: 1.9335\n","Epoch 12: val_loss improved from 2.27868 to 2.25212, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 62ms/step - loss: 1.9335 - val_loss: 2.2521\n","Epoch 13/3000\n","1/1 [==============================] - ETA: 0s - loss: 1.9078\n","Epoch 13: val_loss improved from 2.25212 to 2.22246, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 76ms/step - loss: 1.9078 - val_loss: 2.2225\n","Epoch 14/3000\n","1/1 [==============================] - ETA: 0s - loss: 1.8789\n","Epoch 14: val_loss improved from 2.22246 to 2.18942, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 66ms/step - loss: 1.8789 - val_loss: 2.1894\n","Epoch 15/3000\n","1/1 [==============================] - ETA: 0s - loss: 1.8467\n","Epoch 15: val_loss improved from 2.18942 to 2.15258, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 69ms/step - loss: 1.8467 - val_loss: 2.1526\n","Epoch 16/3000\n","1/1 [==============================] - ETA: 0s - loss: 1.8106\n","Epoch 16: val_loss improved from 2.15258 to 2.11157, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 66ms/step - loss: 1.8106 - val_loss: 2.1116\n","Epoch 17/3000\n","1/1 [==============================] - ETA: 0s - loss: 1.7702\n","Epoch 17: val_loss improved from 2.11157 to 2.06579, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 69ms/step - loss: 1.7702 - val_loss: 2.0658\n","Epoch 18/3000\n","1/1 [==============================] - ETA: 0s - loss: 1.7251\n","Epoch 18: val_loss improved from 2.06579 to 2.01473, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 64ms/step - loss: 1.7251 - val_loss: 2.0147\n","Epoch 19/3000\n","1/1 [==============================] - ETA: 0s - loss: 1.6746\n","Epoch 19: val_loss improved from 2.01473 to 1.95809, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 64ms/step - loss: 1.6746 - val_loss: 1.9581\n","Epoch 20/3000\n","1/1 [==============================] - ETA: 0s - loss: 1.6181\n","Epoch 20: val_loss improved from 1.95809 to 1.89526, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 77ms/step - loss: 1.6181 - val_loss: 1.8953\n","Epoch 21/3000\n","1/1 [==============================] - ETA: 0s - loss: 1.5553\n","Epoch 21: val_loss improved from 1.89526 to 1.82550, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 68ms/step - loss: 1.5553 - val_loss: 1.8255\n","Epoch 22/3000\n","1/1 [==============================] - ETA: 0s - loss: 1.4855\n","Epoch 22: val_loss improved from 1.82550 to 1.74826, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 64ms/step - loss: 1.4855 - val_loss: 1.7483\n","Epoch 23/3000\n","1/1 [==============================] - ETA: 0s - loss: 1.4079\n","Epoch 23: val_loss improved from 1.74826 to 1.66307, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 67ms/step - loss: 1.4079 - val_loss: 1.6631\n","Epoch 24/3000\n","1/1 [==============================] - ETA: 0s - loss: 1.3219\n","Epoch 24: val_loss improved from 1.66307 to 1.56958, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 69ms/step - loss: 1.3219 - val_loss: 1.5696\n","Epoch 25/3000\n","1/1 [==============================] - ETA: 0s - loss: 1.2271\n","Epoch 25: val_loss improved from 1.56958 to 1.46711, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 63ms/step - loss: 1.2271 - val_loss: 1.4671\n","Epoch 26/3000\n","1/1 [==============================] - ETA: 0s - loss: 1.1232\n","Epoch 26: val_loss improved from 1.46711 to 1.35512, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 64ms/step - loss: 1.1232 - val_loss: 1.3551\n","Epoch 27/3000\n","1/1 [==============================] - ETA: 0s - loss: 1.0097\n","Epoch 27: val_loss improved from 1.35512 to 1.23369, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 74ms/step - loss: 1.0097 - val_loss: 1.2337\n","Epoch 28/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.8867\n","Epoch 28: val_loss improved from 1.23369 to 1.10323, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 68ms/step - loss: 0.8867 - val_loss: 1.1032\n","Epoch 29/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.7548\n","Epoch 29: val_loss improved from 1.10323 to 0.96470, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 67ms/step - loss: 0.7548 - val_loss: 0.9647\n","Epoch 30/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.6156\n","Epoch 30: val_loss improved from 0.96470 to 0.82095, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 69ms/step - loss: 0.6156 - val_loss: 0.8209\n","Epoch 31/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.4731\n","Epoch 31: val_loss improved from 0.82095 to 0.68053, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 64ms/step - loss: 0.4731 - val_loss: 0.6805\n","Epoch 32/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.3377\n","Epoch 32: val_loss improved from 0.68053 to 0.55823, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 66ms/step - loss: 0.3377 - val_loss: 0.5582\n","Epoch 33/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.2271\n","Epoch 33: val_loss improved from 0.55823 to 0.47384, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 63ms/step - loss: 0.2271 - val_loss: 0.4738\n","Epoch 34/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.1638\n","Epoch 34: val_loss improved from 0.47384 to 0.44444, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 60ms/step - loss: 0.1638 - val_loss: 0.4444\n","Epoch 35/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.1654\n","Epoch 35: val_loss did not improve from 0.44444\n","1/1 [==============================] - 0s 39ms/step - loss: 0.1654 - val_loss: 0.4687\n","Epoch 36/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.2247\n","Epoch 36: val_loss did not improve from 0.44444\n","1/1 [==============================] - 0s 44ms/step - loss: 0.2247 - val_loss: 0.5186\n","Epoch 37/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.3010\n","Epoch 37: val_loss did not improve from 0.44444\n","1/1 [==============================] - 0s 36ms/step - loss: 0.3010 - val_loss: 0.5492\n","Epoch 38/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.3398\n","Epoch 38: val_loss did not improve from 0.44444\n","1/1 [==============================] - 0s 37ms/step - loss: 0.3398 - val_loss: 0.5519\n","Epoch 39/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.3372\n","Epoch 39: val_loss did not improve from 0.44444\n","1/1 [==============================] - 0s 36ms/step - loss: 0.3372 - val_loss: 0.5293\n","Epoch 40/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.2990\n","Epoch 40: val_loss did not improve from 0.44444\n","1/1 [==============================] - 0s 37ms/step - loss: 0.2990 - val_loss: 0.4917\n","Epoch 41/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.2398\n","Epoch 41: val_loss did not improve from 0.44444\n","1/1 [==============================] - 0s 37ms/step - loss: 0.2398 - val_loss: 0.4526\n","Epoch 42/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.1779\n","Epoch 42: val_loss improved from 0.44444 to 0.42267, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 66ms/step - loss: 0.1779 - val_loss: 0.4227\n","Epoch 43/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.1270\n","Epoch 43: val_loss improved from 0.42267 to 0.40622, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 69ms/step - loss: 0.1270 - val_loss: 0.4062\n","Epoch 44/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0933\n","Epoch 44: val_loss improved from 0.40622 to 0.40265, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 66ms/step - loss: 0.0933 - val_loss: 0.4026\n","Epoch 45/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0765\n","Epoch 45: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 43ms/step - loss: 0.0765 - val_loss: 0.4085\n","Epoch 46/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0727\n","Epoch 46: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 37ms/step - loss: 0.0727 - val_loss: 0.4195\n","Epoch 47/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0770\n","Epoch 47: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 35ms/step - loss: 0.0770 - val_loss: 0.4321\n","Epoch 48/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0848\n","Epoch 48: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 36ms/step - loss: 0.0848 - val_loss: 0.4432\n","Epoch 49/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0926\n","Epoch 49: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 36ms/step - loss: 0.0926 - val_loss: 0.4513\n","Epoch 50/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0983\n","Epoch 50: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 40ms/step - loss: 0.0983 - val_loss: 0.4554\n","Epoch 51/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.1007\n","Epoch 51: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 42ms/step - loss: 0.1007 - val_loss: 0.4555\n","Epoch 52/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0994\n","Epoch 52: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 38ms/step - loss: 0.0994 - val_loss: 0.4520\n","Epoch 53/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0946\n","Epoch 53: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 33ms/step - loss: 0.0946 - val_loss: 0.4458\n","Epoch 54/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0871\n","Epoch 54: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 36ms/step - loss: 0.0871 - val_loss: 0.4379\n","Epoch 55/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0779\n","Epoch 55: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 41ms/step - loss: 0.0779 - val_loss: 0.4296\n","Epoch 56/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0683\n","Epoch 56: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 36ms/step - loss: 0.0683 - val_loss: 0.4220\n","Epoch 57/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0593\n","Epoch 57: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 36ms/step - loss: 0.0593 - val_loss: 0.4163\n","Epoch 58/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0519\n","Epoch 58: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 35ms/step - loss: 0.0519 - val_loss: 0.4131\n","Epoch 59/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0469\n","Epoch 59: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 34ms/step - loss: 0.0469 - val_loss: 0.4126\n","Epoch 60/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0445\n","Epoch 60: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 38ms/step - loss: 0.0445 - val_loss: 0.4146\n","Epoch 61/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0445\n","Epoch 61: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 34ms/step - loss: 0.0445 - val_loss: 0.4182\n","Epoch 62/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0461\n","Epoch 62: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 41ms/step - loss: 0.0461 - val_loss: 0.4224\n","Epoch 63/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0484\n","Epoch 63: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 40ms/step - loss: 0.0484 - val_loss: 0.4262\n","Epoch 64/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0505\n","Epoch 64: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 35ms/step - loss: 0.0505 - val_loss: 0.4286\n","Epoch 65/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0515\n","Epoch 65: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 35ms/step - loss: 0.0515 - val_loss: 0.4293\n","Epoch 66/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0510\n","Epoch 66: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 36ms/step - loss: 0.0510 - val_loss: 0.4282\n","Epoch 67/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0491\n","Epoch 67: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 40ms/step - loss: 0.0491 - val_loss: 0.4257\n","Epoch 68/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0461\n","Epoch 68: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 35ms/step - loss: 0.0461 - val_loss: 0.4223\n","Epoch 69/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0426\n","Epoch 69: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 38ms/step - loss: 0.0426 - val_loss: 0.4188\n","Epoch 70/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0392\n","Epoch 70: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 56ms/step - loss: 0.0392 - val_loss: 0.4156\n","Epoch 71/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0363\n","Epoch 71: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 40ms/step - loss: 0.0363 - val_loss: 0.4130\n","Epoch 72/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0342\n","Epoch 72: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 46ms/step - loss: 0.0342 - val_loss: 0.4113\n","Epoch 73/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0329\n","Epoch 73: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 35ms/step - loss: 0.0329 - val_loss: 0.4103\n","Epoch 74/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0322\n","Epoch 74: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 42ms/step - loss: 0.0322 - val_loss: 0.4098\n","Epoch 75/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0319\n","Epoch 75: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 51ms/step - loss: 0.0319 - val_loss: 0.4095\n","Epoch 76/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0318\n","Epoch 76: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 51ms/step - loss: 0.0318 - val_loss: 0.4094\n","Epoch 77/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0317\n","Epoch 77: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 57ms/step - loss: 0.0317 - val_loss: 0.4092\n","Epoch 78/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0314\n","Epoch 78: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 48ms/step - loss: 0.0314 - val_loss: 0.4090\n","Epoch 79/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0309\n","Epoch 79: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 43ms/step - loss: 0.0309 - val_loss: 0.4086\n","Epoch 80/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0301\n","Epoch 80: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 44ms/step - loss: 0.0301 - val_loss: 0.4082\n","Epoch 81/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0291\n","Epoch 81: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 46ms/step - loss: 0.0291 - val_loss: 0.4077\n","Epoch 82/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0280\n","Epoch 82: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 47ms/step - loss: 0.0280 - val_loss: 0.4073\n","Epoch 83/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0269\n","Epoch 83: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 97ms/step - loss: 0.0269 - val_loss: 0.4071\n","Epoch 84/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0259\n","Epoch 84: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 131ms/step - loss: 0.0259 - val_loss: 0.4070\n","Epoch 85/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0250\n","Epoch 85: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 117ms/step - loss: 0.0250 - val_loss: 0.4072\n","Epoch 86/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0243\n","Epoch 86: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 131ms/step - loss: 0.0243 - val_loss: 0.4075\n","Epoch 87/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0238\n","Epoch 87: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 119ms/step - loss: 0.0238 - val_loss: 0.4079\n","Epoch 88/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0234\n","Epoch 88: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 149ms/step - loss: 0.0234 - val_loss: 0.4083\n","Epoch 89/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0231\n","Epoch 89: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 142ms/step - loss: 0.0231 - val_loss: 0.4087\n","Epoch 90/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0229\n","Epoch 90: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 120ms/step - loss: 0.0229 - val_loss: 0.4089\n","Epoch 91/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0227\n","Epoch 91: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 99ms/step - loss: 0.0227 - val_loss: 0.4089\n","Epoch 92/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0224\n","Epoch 92: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 119ms/step - loss: 0.0224 - val_loss: 0.4088\n","Epoch 93/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0220\n","Epoch 93: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 169ms/step - loss: 0.0220 - val_loss: 0.4086\n","Epoch 94/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0215\n","Epoch 94: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 127ms/step - loss: 0.0215 - val_loss: 0.4082\n","Epoch 95/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0210\n","Epoch 95: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 120ms/step - loss: 0.0210 - val_loss: 0.4077\n","Epoch 96/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0205\n","Epoch 96: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 140ms/step - loss: 0.0205 - val_loss: 0.4072\n","Epoch 97/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0200\n","Epoch 97: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 149ms/step - loss: 0.0200 - val_loss: 0.4068\n","Epoch 98/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0196\n","Epoch 98: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 139ms/step - loss: 0.0196 - val_loss: 0.4064\n","Epoch 99/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0192\n","Epoch 99: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 102ms/step - loss: 0.0192 - val_loss: 0.4061\n","Epoch 100/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0188\n","Epoch 100: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 150ms/step - loss: 0.0188 - val_loss: 0.4059\n","Epoch 101/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0185\n","Epoch 101: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 116ms/step - loss: 0.0185 - val_loss: 0.4058\n","Epoch 102/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0183\n","Epoch 102: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 178ms/step - loss: 0.0183 - val_loss: 0.4057\n","Epoch 103/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0180\n","Epoch 103: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 143ms/step - loss: 0.0180 - val_loss: 0.4056\n","Epoch 104/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0177\n","Epoch 104: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 96ms/step - loss: 0.0177 - val_loss: 0.4056\n","Epoch 105/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0174\n","Epoch 105: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 92ms/step - loss: 0.0174 - val_loss: 0.4056\n","Epoch 106/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0172\n","Epoch 106: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 59ms/step - loss: 0.0172 - val_loss: 0.4056\n","Epoch 107/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0169\n","Epoch 107: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 138ms/step - loss: 0.0169 - val_loss: 0.4056\n","Epoch 108/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0165\n","Epoch 108: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 74ms/step - loss: 0.0165 - val_loss: 0.4056\n","Epoch 109/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0162\n","Epoch 109: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 81ms/step - loss: 0.0162 - val_loss: 0.4057\n","Epoch 110/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0159\n","Epoch 110: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 82ms/step - loss: 0.0159 - val_loss: 0.4057\n","Epoch 111/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0157\n","Epoch 111: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 65ms/step - loss: 0.0157 - val_loss: 0.4057\n","Epoch 112/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0154\n","Epoch 112: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 60ms/step - loss: 0.0154 - val_loss: 0.4057\n","Epoch 113/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0151\n","Epoch 113: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 83ms/step - loss: 0.0151 - val_loss: 0.4057\n","Epoch 114/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0149\n","Epoch 114: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 73ms/step - loss: 0.0149 - val_loss: 0.4057\n","Epoch 115/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0147\n","Epoch 115: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 69ms/step - loss: 0.0147 - val_loss: 0.4057\n","Epoch 116/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0145\n","Epoch 116: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 54ms/step - loss: 0.0145 - val_loss: 0.4056\n","Epoch 117/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0142\n","Epoch 117: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 124ms/step - loss: 0.0142 - val_loss: 0.4055\n","Epoch 118/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0140\n","Epoch 118: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 99ms/step - loss: 0.0140 - val_loss: 0.4054\n","Epoch 119/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0138\n","Epoch 119: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 90ms/step - loss: 0.0138 - val_loss: 0.4053\n","Epoch 120/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0136\n","Epoch 120: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 122ms/step - loss: 0.0136 - val_loss: 0.4052\n","Epoch 121/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0133\n","Epoch 121: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 72ms/step - loss: 0.0133 - val_loss: 0.4051\n","Epoch 122/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0131\n","Epoch 122: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 149ms/step - loss: 0.0131 - val_loss: 0.4050\n","Epoch 123/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0129\n","Epoch 123: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 82ms/step - loss: 0.0129 - val_loss: 0.4049\n","Epoch 124/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0127\n","Epoch 124: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 121ms/step - loss: 0.0127 - val_loss: 0.4048\n","Epoch 125/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0125\n","Epoch 125: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 84ms/step - loss: 0.0125 - val_loss: 0.4047\n","Epoch 126/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0123\n","Epoch 126: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 102ms/step - loss: 0.0123 - val_loss: 0.4046\n","Epoch 127/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0121\n","Epoch 127: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 137ms/step - loss: 0.0121 - val_loss: 0.4045\n","Epoch 128/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0119\n","Epoch 128: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 58ms/step - loss: 0.0119 - val_loss: 0.4045\n","Epoch 129/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0118\n","Epoch 129: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 71ms/step - loss: 0.0118 - val_loss: 0.4044\n","Epoch 130/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0116\n","Epoch 130: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 62ms/step - loss: 0.0116 - val_loss: 0.4043\n","Epoch 131/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0114\n","Epoch 131: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 114ms/step - loss: 0.0114 - val_loss: 0.4042\n","Epoch 132/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0112\n","Epoch 132: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 129ms/step - loss: 0.0112 - val_loss: 0.4042\n","Epoch 133/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0111\n","Epoch 133: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 46ms/step - loss: 0.0111 - val_loss: 0.4041\n","Epoch 134/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0109\n","Epoch 134: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 89ms/step - loss: 0.0109 - val_loss: 0.4040\n","Epoch 135/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0107\n","Epoch 135: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 196ms/step - loss: 0.0107 - val_loss: 0.4040\n","Epoch 136/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0106\n","Epoch 136: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 115ms/step - loss: 0.0106 - val_loss: 0.4040\n","Epoch 137/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0104\n","Epoch 137: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 86ms/step - loss: 0.0104 - val_loss: 0.4040\n","Epoch 138/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0103\n","Epoch 138: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 133ms/step - loss: 0.0103 - val_loss: 0.4040\n","Epoch 139/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0101\n","Epoch 139: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 106ms/step - loss: 0.0101 - val_loss: 0.4040\n","Epoch 140/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0100\n","Epoch 140: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 94ms/step - loss: 0.0100 - val_loss: 0.4040\n","Epoch 141/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0099\n","Epoch 141: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 178ms/step - loss: 0.0099 - val_loss: 0.4040\n","Epoch 142/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0097\n","Epoch 142: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 48ms/step - loss: 0.0097 - val_loss: 0.4041\n","Epoch 143/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0096\n","Epoch 143: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 115ms/step - loss: 0.0096 - val_loss: 0.4041\n","Epoch 144/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0095\n","Epoch 144: val_loss did not improve from 0.40265\n","1/1 [==============================] - 0s 53ms/step - loss: 0.0095 - val_loss: 0.4041\n","1/1 [==============================] - 0s 454ms/step - loss: 0.2811\n","loss_and_metrics : 0.28114110231399536\n","1/1 [==============================] - 0s 290ms/step\n"]}],"source":["import scipy\n","import numpy\n","import h5py\n","\n","#import tensorflow\n","from tensorflow import keras\n","\n","#print('scipy ' + scipy.__version__)\n","#print('numpy ' + numpy.__version__)\n","#print('h5py ' + h5py.__version__)\n","\n","#print('tensorflow ' + tensorflow.__version__)\n","#print('keras ' + keras.__version__)\n","\n","import scipy.io\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Activation\n","#from keras.optimizers import SGD\n","from tensorflow.keras.optimizers import Adam\n","#from keras.optimizers import Nadam\n","#from keras.optimizers import RMSprop\n","from tensorflow.keras.optimizers import Adamax\n","from tensorflow.keras.datasets import cifar10\n","#error발생: from tensorflow.keras.utils import np_utils\n","from tensorflow.keras.utils import to_categorical\n","\n","\n","train_x_data = scipy.io.loadmat('ml_detect_in_train.mat')\n","train_y_data = scipy.io.loadmat('ml_detect_out_train.mat')\n","\n","train_x = train_x_data['in']\n","train_y = train_y_data['out']\n","\n","\n","\n","val_x_data = scipy.io.loadmat('ml_detect_in_val.mat')\n","val_y_data = scipy.io.loadmat('ml_detect_out_val.mat')\n","\n","val_x = val_x_data['in']\n","val_y = val_y_data['out']\n","\n","\n","# relu, tanh, elu, selu\n","\n","model = Sequential()\n","model.add(Dense(units=100, input_dim=16, activation=\"relu\", kernel_initializer=\"normal\"))\n","#model.add(Dropout(0.5))\n","model.add(Dense(units=100, activation=\"relu\", kernel_initializer=\"normal\"))\n","#model.add(Dropout(0.5))\n","model.add(Dense(units=100, activation=\"relu\", kernel_initializer=\"normal\"))\n","#model.add(Dropout(0.5))\n","model.add(Dense(units=100, activation=\"relu\", kernel_initializer=\"normal\"))\n","#model.add(Dropout(0.5))\n","model.add(Dense(units=100, activation=\"relu\", kernel_initializer=\"normal\"))\n","#model.add(Dropout(0.5))\n","model.add(Dense(units=4, activation=\"linear\", kernel_initializer='normal'))\n","\n","\n","#model.compile(loss='mean_squared_error', optimizer='adam')\n","model.compile(loss='mean_squared_error', optimizer='adamax')\n","\n","#model.fit(train_x, train_y, epochs=1000, batch_size=32)\n","\n","from keras.callbacks import EarlyStopping\n","from keras.callbacks import ModelCheckpoint\n","early_stopping = EarlyStopping(patience = 100) # 조기종료 콜백함수 정의, 100 에포크 동안은 기다림\n","checkpoint_callback = ModelCheckpoint('hl5_0100.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n","model.fit(train_x, train_y, epochs=3000, batch_size=32, validation_data=(val_x, val_y), callbacks=[early_stopping, checkpoint_callback])\n","\n","\n","from keras.models import load_model\n","model_cp = load_model('hl5_0100.h5')\n","\n","test_x_data = scipy.io.loadmat('ml_detect_in_test.mat')\n","test_y_data = scipy.io.loadmat('ml_detect_out_test.mat')\n","test_x = test_x_data['in']\n","test_y = test_y_data['out']\n","\n","loss_and_metrics = model_cp.evaluate(test_x, test_y, batch_size=32)\n","\n","print('loss_and_metrics : ' + str(loss_and_metrics))\n","\n","\n","yhat=model_cp.predict(test_x)\n","scipy.io.savemat('hl5_0500_pred.mat',dict([('predict_ch', yhat) ]))\n"]}]}